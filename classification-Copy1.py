#!/usr/bin/env python
# coding: utf-8

# In[1]:


import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import pathlib
import numpy as np
import PIL
from tensorflow import keras
from tensorflow.keras.models import Sequential
from sklearn.metrics import confusion_matrix


# In[2]:


data_dir = r"E:\tdkMalwareKepek\hatvannegysorted"


# In[3]:


data_dir = pathlib.Path(data_dir)
image_count = len(list(data_dir.glob('*/*.png')))
print(image_count)


# In[4]:


batch_size = 32
img_height = 64
img_width = 64


# In[5]:


train_dataset = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)


# In[6]:


validation_dataset = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)


# In[7]:


class_names = train_dataset.class_names
print(class_names)
class_names_validation = validation_dataset.class_names
print(class_names_validation)


# In[8]:


import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")


# In[9]:


for image_batch, labels_batch in train_dataset:
  print(image_batch.shape)
  print(labels_batch.shape)
  break


# In[10]:


AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)


# In[11]:


normalization_layer = layers.Rescaling(1./255)


# In[12]:


normalized_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_dataset))
first_image = image_batch[0]
print(np.min(first_image), np.max(first_image))


# In[13]:


num_classes = len(class_names)

model = Sequential([
  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes, activation="softmax")
])


# In[14]:


model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])


# In[15]:


model.summary()


# In[16]:


train_labels = tf.concat([y for x, y in train_dataset], axis=0)
print(train_labels)


# In[17]:


from sklearn.utils.class_weight import compute_class_weight
import numpy as np
class_weights = compute_class_weight('balanced', classes=np.unique(train_labels.numpy()), y=train_labels.numpy())
class_weights_dict = dict(enumerate(class_weights))
print(class_weights_dict)


# In[31]:


epochs=50
history = model.fit(
  train_dataset,
  class_weight=class_weights_dict,
  validation_data=validation_dataset,
  epochs=epochs
)


# In[19]:


y_pred = model.predict(validation_dataset)
y_pred


# In[20]:


predicted_categories = tf.argmax(y_pred, axis=1)
predicted_categories


# In[21]:


true_categories = tf.concat([y for x, y in validation_dataset], axis=0)
true_categories


# In[22]:


cf = confusion_matrix(true_categories, predicted_categories, normalize='true')
cf


# In[23]:


import seaborn as sn
import pandas as pd


# In[24]:


columns = class_names_validation
table_data = pd.DataFrame(cf, columns, columns)
sn.set(font_scale=1.2)
sn.heatmap(table_data, annot=True, annot_kws={"size": 8}) # font size
plt.xlabel("Predicted class")
plt.ylabel("True class")

plt.show()


# In[25]:


acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()


# In[26]:


tf.keras.utils.plot_model(model, to_file="bytemodell.png", show_shapes=True)


# In[ ]:




